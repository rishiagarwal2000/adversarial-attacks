{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cw-ead-attack.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RbAcgE4xF_OM","executionInfo":{"status":"ok","timestamp":1620832030787,"user_tz":-330,"elapsed":3794,"user":{"displayName":"Rishi Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRcXOJWUhOHIm4vHm5hpsSwL72zyQK06beQCm-Dg=s64","userId":"04123742633303063791"}},"outputId":"9bb2cc55-aadf-481b-eaad-6de4d9c71e4a"},"source":["import sys\n","import tensorflow as tf\n","tf.compat.v1.disable_v2_behavior()\n","import numpy as np"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GrSJxAwZDGXc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620915783634,"user_tz":-330,"elapsed":3080,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}},"outputId":"0c0da2ab-fe50-418a-91fc-fcfb92ca3ea5"},"source":["import sys\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import SGD\n","\n","import tensorflow as tf\n","tf.compat.v1.disable_v2_behavior()\n","tf.compat.v1.enable_eager_execution(\n","    config=None, device_policy=None, execution_mode=None\n",")\n","import keras"],"execution_count":1,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o_sSFHr0DJfD","executionInfo":{"status":"ok","timestamp":1620920719620,"user_tz":-330,"elapsed":1717,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}}},"source":["mnist = tf.keras.datasets.mnist\n","\n","(train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n","train_data, test_data = train_data / 255.0, test_data / 255.0\n","\n","# Add a channels dimension\n","train_data = train_data[..., tf.newaxis].astype(\"float32\")\n","test_data = test_data[..., tf.newaxis].astype(\"float32\")\n","\n","\n","VALIDATION_SIZE = 5000\n","validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n","validation_labels = train_labels[:VALIDATION_SIZE]\n","train_data = train_data[VALIDATION_SIZE:, :, :, :]\n","train_labels = train_labels[VALIDATION_SIZE:]\n","params = [32, 32, 64, 64, 200, 200]\n","batch_size = 128\n","\n","# Prepare the training dataset.\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n","train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n","\n","# Prepare the validation dataset.\n","val_dataset = tf.data.Dataset.from_tensor_slices((validation_data, validation_labels))\n","val_dataset = val_dataset.batch(batch_size)\n","\n","class MNIST:\n","    def __init__(self, train_data, train_labels, validation_data, validation_labels, test_data, test_labels):\n","        self.train_data = train_data\n","        self.train_labels = train_labels\n","        self.test_data = test_data\n","        self.test_labels = test_labels\n","        self.validation_data = validation_data\n","        self.validation_labels = validation_labels\n","\n","mnist_data = MNIST(train_data, train_labels, validation_data, validation_labels, test_data, test_labels)\n","\n","\n","def show(img):\n","    \"\"\"\n","    Show MNSIT digits in the console.\n","    \"\"\"\n","    remap = \"  .*#\"+\"#\"*100\n","    img = (img.flatten()+.5)*3\n","    if len(img) != 784: return\n","    print(\"START\")\n","    for i in range(28):\n","        print(\"\".join([remap[int(round(x))] for x in img[i*28:i*28+28]]))\n","\n","def get_model(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n","    \"\"\"\n","    Standard neural network training procedure.\n","    \"\"\"\n","    model = Sequential()\n","\n","    print(data.train_data.shape)\n","    \n","    model.add(Conv2D(params[0], (3, 3),\n","                            input_shape=data.train_data.shape[1:]))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(params[1], (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Conv2D(params[2], (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(params[3], (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Flatten())\n","    model.add(Dense(params[4]))\n","    model.add(Activation('relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(params[5]))\n","    model.add(Activation('relu'))\n","    model.add(Dense(10))\n","    # model.add(Activation('softmax'))\n","\n","    return model"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HbDZU8IbDVaQ","executionInfo":{"status":"ok","timestamp":1620844773149,"user_tz":-330,"elapsed":9415,"user":{"displayName":"Rishi Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRcXOJWUhOHIm4vHm5hpsSwL72zyQK06beQCm-Dg=s64","userId":"04123742633303063791"}},"outputId":"1851e348-7c39-44dd-c724-b7a2bdcac16e"},"source":["basic_model = get_model(mnist_data, \"mnistModel\", params)\n","\n","import keras\n","# Instantiate an optimizer to train the model.\n","optimizer = keras.optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9)\n","# Instantiate a loss function.\n","loss_fn1 = tf.nn.softmax_cross_entropy_with_logits\n","loss_fn2 = keras.losses.BinaryCrossentropy()\n","loss_fn3 = keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n","\n","# Prepare the metrics.\n","train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","\n","@tf.function\n","def train_step(x1, y, yprob):\n","    with tf.GradientTape() as tape:\n","        logits1 = basic_model(x1, training=True)\n","        loss_value = tf.reduce_mean(loss_fn1(yprob, logits1))\n","    grads = tape.gradient(loss_value, basic_model.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, basic_model.trainable_weights))\n","    train_acc_metric.update_state(y, logits1)\n","    return loss_value\n","\n","@tf.function\n","def test_step(x, y):\n","    val_logits = basic_model(x, training=False)\n","    val_acc_metric.update_state(y, val_logits)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(55000, 28, 28, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lNVtyMW8hXrD"},"source":["print(basic_model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aq5xeIowFhjR","executionInfo":{"status":"ok","timestamp":1620844848924,"user_tz":-330,"elapsed":56563,"user":{"displayName":"Rishi Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRcXOJWUhOHIm4vHm5hpsSwL72zyQK06beQCm-Dg=s64","userId":"04123742633303063791"}},"outputId":"28815843-4d8f-4e69-80f5-8d38ed213470"},"source":["# Training model\n","import time\n","import math \n","std = 0.01\n","epochs = 5\n","\n","total_steps = sum(1 for _ in train_dataset)\n","\n","for epoch in range(epochs):\n","    start_time = time.time()\n","\n","    # Iterate over the batches of the dataset.\n","    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","        # Compute loss\n","        loss_value = train_step(x_batch_train, y_batch_train, tf.one_hot(y_batch_train, 10))\n","        print('\\r', \"Epoch %d\" % (epoch,), 'Training step:', step+1, f'/{total_steps}', 'Loss:', float(loss_value), 'Acc:', float(train_acc_metric.result()), end='')\n","    \n","    # Display metrics at the end of each epoch.\n","    train_acc = train_acc_metric.result()\n","    print(\"\\nTraining acc over epoch: %.4f\" % (float(train_acc),), end=' ')\n","\n","    # Reset training metrics at the end of each epoch\n","    train_acc_metric.reset_states()\n","\n","    # Run a validation loop at the end of each epoch.\n","    for x_batch_val, y_batch_val in val_dataset:\n","        test_step(x_batch_val, y_batch_val)\n","    val_acc = val_acc_metric.result()\n","    val_acc_metric.reset_states()\n","    print(\"Validation acc: %.4f\" % (float(val_acc),), end=' ')\n","    print(\"Time taken: %.2fs\\n\" % (time.time() - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" Epoch 0 Training step: 430 /430 Loss: 0.14182710647583008 Acc: 0.8337273001670837\n","Training acc over epoch: 0.8337 Validation acc: 0.9726 Time taken: 37.46s\n","\n"," Epoch 1 Training step: 430 /430 Loss: 0.1076287105679512 Acc: 0.96143639087677\n","Training acc over epoch: 0.9614 Validation acc: 0.9810 Time taken: 4.39s\n","\n"," Epoch 2 Training step: 430 /430 Loss: 0.07328467071056366 Acc: 0.9723636507987976\n","Training acc over epoch: 0.9724 Validation acc: 0.9856 Time taken: 4.34s\n","\n"," Epoch 3 Training step: 430 /430 Loss: 0.013835951685905457 Acc: 0.977581799030304\n","Training acc over epoch: 0.9776 Validation acc: 0.9860 Time taken: 4.41s\n","\n"," Epoch 4 Training step: 430 /430 Loss: 0.03370736539363861 Acc: 0.9815090894699097\n","Training acc over epoch: 0.9815 Validation acc: 0.9876 Time taken: 4.41s\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CVs0yq4cHT3c","executionInfo":{"status":"ok","timestamp":1620915903399,"user_tz":-330,"elapsed":24996,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}},"outputId":"d72fada4-d8ff-4045-f619-34f590783e0c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tq7B9Pr6HGOI","executionInfo":{"status":"ok","timestamp":1620917829855,"user_tz":-330,"elapsed":2273,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}},"outputId":"94b9403e-6f32-45cc-db83-0e4f0496bccf"},"source":["basic_model = tf.keras.models.load_model('/content/drive/MyDrive/CS726/basic_model')\n","pgd_model = tf.keras.models.load_model('/content/drive/MyDrive/CS726/pgd_model')\n","stab_model = tf.keras.models.load_model('/content/drive/MyDrive/CS726/stab_model')"],"execution_count":39,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bJQnJOGIJVR3","executionInfo":{"status":"ok","timestamp":1620916398207,"user_tz":-330,"elapsed":1180,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}}},"source":["import math"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZByttPDlyZ6R"},"source":["CONFIDENCE = 0\n","LEARNING_RATE = 1e-2\n","CONST = 1\n","boxmin = -0.5 \n","boxmax = 0.5\n","boxmul = (boxmax - boxmin) / 2.\n","boxplus = (boxmin + boxmax) / 2.\n","\n","batch_size = 128\n","k = math.ceil(test_data.shape[0] // batch_size)\n","cw_adv_basic = []\n","for i in range(k):\n","  imgs = test_data[i*batch_size:min((i+1)*batch_size,test_data.shape[0]), :,:,:]\n","  yprob = tf.one_hot(test_labels[i*batch_size:min((i+1)*batch_size,test_data.shape[0])], 10)\n","  print(i*batch_size, min((i+1)*batch_size,test_data.shape[0]))\n","  print(yprob.shape, imgs.shape)\n","  # print(np.arctanh((imgs - boxplus) / boxmul * 0.999999))\n","  timg = tf.convert_to_tensor(np.arctanh((imgs - 0.5) / 0.5 * 0.999999))\n","  modifier = np.zeros(imgs.shape,dtype=np.float32)\n","  modifier_tensor = tf.Variable(modifier)\n","\n","  optimizer = keras.optimizers.Adam(LEARNING_RATE)\n","  for i in range(1000):\n","      with tf.GradientTape() as t:\n","          t.watch(modifier_tensor)\n","          newimg = tf.tanh(modifier_tensor + timg) * boxmul + 0.5\n","          # newimg = tf.tanh(modifier_tensor + 1) * boxmul\n","          logits1 = basic_model(newimg, training=True)\n","          l2dist = tf.reduce_sum(tf.square(newimg-(tf.tanh(timg) * 0.5 + 0.5)),[1,2,3])\n","          loss2 = tf.reduce_sum(l2dist) # sum l2 distance\n","          # loss1 = loss_fn3(y, logits1)\n","          real = tf.reduce_sum((yprob)*logits1,1)\n","          other = tf.reduce_max((1-yprob)*logits1 - (yprob*10000),1)\n","          loss1 = CONST * tf.reduce_sum(tf.maximum(0.0, real-other+CONFIDENCE))\n","          loss_value = loss1 + loss2\n","      # result = loss_value\n","      grads = t.gradient(loss_value, modifier_tensor)\n","\n","      optimizer.apply_gradients(zip([grads], [modifier_tensor]))\n","      print('\\r', \"i %d\" % (i,), 'Loss 1:', float(loss1), 'Loss 2:', float(loss2), 'Loss:', float(loss_value), end='')\n","  cw_adv_basic.append((tf.tanh(modifier_tensor + timg) * boxmul + 0.5).numpy())\n","\n","cw_adv_basic =  np.concatenate(cw_adv_basic, axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eyg7OMaULCq2","executionInfo":{"status":"ok","timestamp":1620917574810,"user_tz":-330,"elapsed":16583,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}},"outputId":"54de8973-e80d-46f6-9734-ed13d45c922d"},"source":["CONFIDENCE = 0\n","LEARNING_RATE = 1e-2\n","CONST = 500\n","boxmin = -0.5 \n","boxmax = 0.5\n","boxmul = (boxmax - boxmin) / 2.\n","boxplus = (boxmin + boxmax) / 2.\n","\n","batch_size = 128\n","imgs = test_data[:batch_size, :,:,:]\n","yprob = tf.one_hot(test_labels[:batch_size], 10)\n","print(yprob.shape, imgs.shape)\n","# print(np.arctanh((imgs - boxplus) / boxmul * 0.999999))\n","timg = tf.convert_to_tensor(np.arctanh((imgs - 0.5) / 0.5 * 0.999999))\n","modifier = np.zeros((batch_size, 28, 28, 1),dtype=np.float32)\n","modifier_tensor = tf.Variable(modifier)\n","\n","optimizer = keras.optimizers.Adam(LEARNING_RATE)\n","for i in range(1000):\n","    with tf.GradientTape() as t:\n","        t.watch(modifier_tensor)\n","        newimg = tf.tanh(modifier_tensor + timg) * boxmul + 0.5\n","        # newimg = tf.tanh(modifier_tensor + 1) * boxmul\n","        logits1 = basic_model(newimg, training=True)\n","        l2dist = tf.reduce_sum(tf.square(newimg-(tf.tanh(timg) * 0.5 + 0.5)),[1,2,3])\n","        loss2 = tf.reduce_sum(l2dist) # sum l2 distance\n","        # loss1 = loss_fn3(y, logits1)\n","        real = tf.reduce_sum((yprob)*logits1,1)\n","        other = tf.reduce_max((1-yprob)*logits1 - (yprob*10000),1)\n","        loss1 = CONST * tf.reduce_sum(tf.maximum(0.0, real-other+CONFIDENCE))\n","        loss_value = loss1 + loss2\n","    # result = loss_value\n","    grads = t.gradient(loss_value, modifier_tensor)\n","\n","    optimizer.apply_gradients(zip([grads], [modifier_tensor]))\n","    print('\\r', \"i %d\" % (i,), 'Loss 1:', float(loss1), 'Loss 2:', float(loss2), 'Loss:', float(loss_value), end='')\n","cw_adv_basic = (tf.tanh(modifier_tensor + timg) * boxmul + 0.5).numpy()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["(128, 10) (128, 28, 28, 1)\n"," i 999 Loss 1: 10999.4326171875 Loss 2: 1154.385009765625 Loss: 12153.8173828125"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QqXs_o9kH5Yy","executionInfo":{"status":"ok","timestamp":1620917858296,"user_tz":-330,"elapsed":17009,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}},"outputId":"d713b66b-8e3d-460d-f1b0-bedff0e89df0"},"source":["CONFIDENCE = 0\n","LEARNING_RATE = 1e-2\n","CONST = 500\n","boxmin = -0.5 \n","boxmax = 0.5\n","boxmul = (boxmax - boxmin) / 2.\n","boxplus = (boxmin + boxmax) / 2.\n","\n","batch_size = 128\n","imgs = train_data[:batch_size, :,:,:]\n","yprob = tf.one_hot(train_labels[:batch_size], 10)\n","print(yprob.shape, imgs.shape)\n","# print(np.arctanh((imgs - boxplus) / boxmul * 0.999999))\n","timg = tf.convert_to_tensor(np.arctanh((imgs - 0.5) / 0.5 * 0.999999))\n","modifier = np.zeros((batch_size, 28, 28, 1),dtype=np.float32)\n","modifier_tensor = tf.Variable(modifier)\n","\n","optimizer = keras.optimizers.Adam(LEARNING_RATE)\n","for i in range(1000):\n","    with tf.GradientTape() as t:\n","        t.watch(modifier_tensor)\n","        newimg = tf.tanh(modifier_tensor + timg) * boxmul + 0.5\n","        # newimg = tf.tanh(modifier_tensor + 1) * boxmul\n","        logits1 = pgd_model(newimg, training=True)\n","        l2dist = tf.reduce_sum(tf.square(newimg-(tf.tanh(timg) * 0.5 + 0.5)),[1,2,3])\n","        loss2 = tf.reduce_sum(l2dist) # sum l2 distance\n","        # loss1 = loss_fn3(y, logits1)\n","        real = tf.reduce_sum((yprob)*logits1,1)\n","        other = tf.reduce_max((1-yprob)*logits1 - (yprob*10000),1)\n","        loss1 = CONST * tf.reduce_sum(tf.maximum(0.0, real-other+CONFIDENCE))\n","        loss_value = loss1 + loss2\n","    # result = loss_value\n","    grads = t.gradient(loss_value, modifier_tensor)\n","\n","    optimizer.apply_gradients(zip([grads], [modifier_tensor]))\n","    print('\\r', \"i %d\" % (i,), 'Loss 1:', float(loss1), 'Loss 2:', float(loss2), 'Loss:', float(loss_value), end='')\n","cw_adv_pgd = (tf.tanh(modifier_tensor + timg) * boxmul + 0.5).numpy()"],"execution_count":40,"outputs":[{"output_type":"stream","text":["(128, 10) (128, 28, 28, 1)\n"," i 999 Loss 1: 19248.87890625 Loss 2: 1048.982177734375 Loss: 20297.861328125"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-If89jsIH6Cu","executionInfo":{"status":"ok","timestamp":1620917657546,"user_tz":-330,"elapsed":16933,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}},"outputId":"e121850b-98e6-4bc0-8b54-91ed2f2dd51a"},"source":["CONFIDENCE = 0\n","LEARNING_RATE = 1e-2\n","CONST = 500\n","boxmin = -0.5 \n","boxmax = 0.5\n","boxmul = (boxmax - boxmin) / 2.\n","boxplus = (boxmin + boxmax) / 2.\n","\n","batch_size = 128\n","imgs = test_data[:batch_size, :,:,:]\n","yprob = tf.one_hot(test_labels[:batch_size], 10)\n","print(yprob.shape, imgs.shape)\n","# print(np.arctanh((imgs - boxplus) / boxmul * 0.999999))\n","timg = tf.convert_to_tensor(np.arctanh((imgs - 0.5) / 0.5 * 0.999999))\n","modifier = np.zeros((batch_size, 28, 28, 1),dtype=np.float32)\n","modifier_tensor = tf.Variable(modifier)\n","\n","optimizer = keras.optimizers.Adam(LEARNING_RATE)\n","for i in range(1000):\n","    with tf.GradientTape() as t:\n","        t.watch(modifier_tensor)\n","        newimg = tf.tanh(modifier_tensor + timg) * boxmul + 0.5\n","        # newimg = tf.tanh(modifier_tensor + 1) * boxmul\n","        logits1 = stab_model(newimg, training=True)\n","        l2dist = tf.reduce_sum(tf.square(newimg-(tf.tanh(timg) * 0.5 + 0.5)),[1,2,3])\n","        loss2 = tf.reduce_sum(l2dist) # sum l2 distance\n","        # loss1 = loss_fn3(y, logits1)\n","        real = tf.reduce_sum((yprob)*logits1,1)\n","        other = tf.reduce_max((1-yprob)*logits1 - (yprob*10000),1)\n","        loss1 = CONST * tf.reduce_sum(tf.maximum(0.0, real-other+CONFIDENCE))\n","        loss_value = loss1 + loss2\n","    # result = loss_value\n","    grads = t.gradient(loss_value, modifier_tensor)\n","\n","    optimizer.apply_gradients(zip([grads], [modifier_tensor]))\n","    print('\\r', \"i %d\" % (i,), 'Loss 1:', float(loss1), 'Loss 2:', float(loss2), 'Loss:', float(loss_value), end='')\n","cw_adv_stab = (tf.tanh(modifier_tensor + timg) * boxmul + 0.5).numpy()"],"execution_count":34,"outputs":[{"output_type":"stream","text":["(128, 10) (128, 28, 28, 1)\n"," i 999 Loss 1: 10022.5361328125 Loss 2: 1400.6063232421875 Loss: 11423.142578125"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"liDj2gP9VLQ0","executionInfo":{"status":"ok","timestamp":1620920824883,"user_tz":-330,"elapsed":84011,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}},"outputId":"64b7800a-6319-4730-bac6-c1c7f9a7e5af"},"source":["CONFIDENCE = 0\n","LEARNING_RATE = 1e-2\n","boxmin = -0.5 \n","boxmax = 0.5\n","boxmul = (boxmax - boxmin) / 2.\n","boxplus = (boxmin + boxmax) / 2.\n","\n","cw_adv_stab = np.copy(test_data[:batch_size,:,:,:])\n","\n","for CONST_FACTOR in range(5):\n","  CONST = 1 + CONST_FACTOR * 100\n","  print(CONST)\n","  batch_size = 128\n","  imgs = test_data[:batch_size, :,:,:]\n","  yprob = tf.one_hot(test_labels[:batch_size], 10)\n","  print(yprob.shape, imgs.shape)\n","  # print(np.arctanh((imgs - boxplus) / boxmul * 0.999999))\n","  timg = tf.convert_to_tensor(np.arctanh((imgs - 0.5) / 0.5 * 0.999999))\n","  modifier = np.zeros((batch_size, 28, 28, 1),dtype=np.float32)\n","  modifier_tensor = tf.Variable(modifier)\n","\n","  optimizer = keras.optimizers.Adam(LEARNING_RATE)\n","  for i in range(1000):\n","      with tf.GradientTape() as t:\n","          t.watch(modifier_tensor)\n","          newimg = tf.tanh(modifier_tensor + timg) * boxmul + 0.5\n","          # newimg = tf.tanh(modifier_tensor + 1) * boxmul\n","          logits1 = stab_model(newimg, training=True)\n","          l2dist = tf.reduce_sum(tf.square(newimg-(tf.tanh(timg) * 0.5 + 0.5)),[1,2,3])\n","          loss2 = tf.reduce_sum(l2dist) # sum l2 distance\n","          # loss1 = loss_fn3(y, logits1)\n","          real = tf.reduce_sum((yprob)*logits1,1)\n","          other = tf.reduce_max((1-yprob)*logits1 - (yprob*10000),1)\n","          loss1 = CONST * tf.reduce_sum(tf.maximum(0.0, real-other+CONFIDENCE))\n","          loss_value = loss1 + loss2\n","      # result = loss_value\n","      grads = t.gradient(loss_value, modifier_tensor)\n","\n","      optimizer.apply_gradients(zip([grads], [modifier_tensor]))\n","      print('\\r', \"i %d\" % (i,), 'Loss 1:', float(loss1), 'Loss 2:', float(loss2), 'Loss:', float(loss_value), end='')\n","  cw_adv_stab_temp = (tf.tanh(modifier_tensor + timg) * boxmul + 0.5).numpy()\n","  for i in range(batch_size):\n","    if np.argmax(stab_model(cw_adv_stab[i,:,:,:][np.newaxis,:,:,:])) == test_labels[i] or (np.argmax(stab_model(cw_adv_stab_temp[i,:,:,:][np.newaxis,:,:,:])) != test_labels[i] and np.sum((cw_adv_stab_temp[i,:,:,:]-test_data[i,:,:,:])**2) < np.sum((cw_adv_stab[i,:,:,:]-test_data[i,:,:,:])**2)):\n","      cw_adv_stab[i] = cw_adv_stab_temp[i]      \n","# cw_adv_stab = (tf.tanh(modifier_tensor + timg) * boxmul + 0.5).numpy()"],"execution_count":71,"outputs":[{"output_type":"stream","text":["1\n","(128, 10) (128, 28, 28, 1)\n"," i 999 Loss 1: 122.79732513427734 Loss 2: 1.5542774200439453 Loss: 124.35160064697266101\n","(128, 10) (128, 28, 28, 1)\n"," i 999 Loss 1: 5465.60791015625 Loss 2: 496.125732421875 Loss: 5961.7333984375201\n","(128, 10) (128, 28, 28, 1)\n"," i 999 Loss 1: 8092.18359375 Loss 2: 788.72900390625 Loss: 8880.912109375301\n","(128, 10) (128, 28, 28, 1)\n"," i 999 Loss 1: 8999.9931640625 Loss 2: 1075.9632568359375 Loss: 10075.9560546875401\n","(128, 10) (128, 28, 28, 1)\n"," i 999 Loss 1: 10139.525390625 Loss 2: 1252.7313232421875 Loss: 11392.2568359375"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"id":"wUaUY5U5BWCb","executionInfo":{"status":"ok","timestamp":1620920829716,"user_tz":-330,"elapsed":981,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}},"outputId":"9c6aa3cc-2c4c-4e85-8e88-f69a0570ea3a"},"source":["i = 35\n","x_l2 = cw_adv_stab[i,:,:,:]\n","# show(x_l2)\n","\n","import matplotlib.pyplot as plt\n","\n","im_l2 = x_l2.reshape(28, 28)\n","plt.gray()\n","plt.imshow(im_l2)\n","plt.figure()\n","plt.imshow(test_data[i,:,:,:].reshape(28,28))\n","print(test_labels[i])\n","print(np.sum((x_l2-test_data[i,:,:,:])**2))"],"execution_count":72,"outputs":[{"output_type":"stream","text":["2\n","30.09211\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPsUlEQVR4nO3da4wVdZrH8d/DRRCUiOI2bYMLM+IL3ERnJca4RGczgaAm4LyZDInKZifLJI7JTLLGNWyMxkscNustGo1MMMNsZiGTeH0BmXFxghITtCWsXFy8C5KGFhRhuNM8++IUuy12/as5p86p0/18P0mn+9TTdc7DSf+oOvWvqr+5uwAMfyOqbgBAaxB2IAjCDgRB2IEgCDsQxKhWvpiZcegfaDJ3t4GWN7RlN7N5ZrbdzD4ys3saeS4AzWX1jrOb2UhJH0iaI+kLSe9IWuju2xLrsGUHmqwZW/ZrJH3k7p+4+3FJqyQtaOD5ADRRI2HvkrSz3+MvsmXfYmaLzazbzLobeC0ADWr6ATp3XyZpmcRuPFClRrbsuyRN7fd4SrYMQBtqJOzvSJphZtPN7BxJP5X0ajltAShb3bvx7n7SzO6U9EdJIyU97+5bS+sMQKnqHnqr68X4zA40XVNOqgEwdBB2IAjCDgRB2IEgCDsQBGEHgmjp9exAK40alf/nPXHixOS6+/btS9ZPnTpVV09VYssOBEHYgSAIOxAEYQeCIOxAEIQdCIKr3jBsmQ148ZckacqUKcl1L7roomR9x44dyfr+/fuT9WYO3XHVGxAcYQeCIOxAEIQdCIKwA0EQdiAIwg4EwSWuJZg8eXKyPmbMmGR9z549yfrRo0fPuqfTUpd5StKtt96arF955ZXJ+ksvvZSsL1myJLf22GOPJdc9ceJEsn7jjTcm60uXLs2t9fb2Jtft6vrOTGbfcu655ybrRePsVWDLDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBcD17pmg8esSI/P8XZ86cmVx3+vTpyfrOnTuT9e7u7mR9zZo1ubXDhw8n1922bVuy/vbbbyfrRb2nXr+vry+5blF97NixyXpqHP7RRx9Nrlt07kTROPrx48eT9WbKu569oZNqzOwzSQcl9Uk66e6zGnk+AM1Txhl0f+/ue0t4HgBNxGd2IIhGw+6S/mRm75rZ4oF+wcwWm1m3maU/eAJoqkZ342e7+y4z+ytJr5nZ/7j7G/1/wd2XSVomtfcBOmC4a2jL7u67su+9kl6SdE0ZTQEoX91hN7PxZnb+6Z8lzZW0pazGAJSr7nF2M/uealtzqfZx4D/d/eGCdYblbnzR9erHjh1L1j/++ONkfevWrcn6unXrcmvTpk1Lrnvw4MFk/amnnkrWi67Fb+b90ceNG5esp84hKLpv/MqVK5P12267LVmvUunj7O7+iaT0nQ0AtA2G3oAgCDsQBGEHgiDsQBCEHQiCW0mXoGho7a677krW33rrrWR93rx5yfqbb76ZWyuaerhoaK2npydZr9KCBQuS9SNHjuTW1q9fn1x3+fLldfXUztiyA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQjLOXoKOjI1lPjYNL0s0335ysf/3118n63Llz66pJktmAV0O2xIQJE5L1AwcOJOtFl6Gm1r/00kuT627cuDFZH4rYsgNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEEzZPEjnn39+bu32229Prlt0O+XVq1cn688++2yyPn/+/NzayJEjk+sWXYs/lE2aNCm31tXVlVz3gw8+SNZT18pXLe9W0mzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIxtkH6bLLLsutPffcc8l177333mS96L7xRUaPHp1bO3HiREPPPZSdd955ddUkaffu3WW30zJ1j7Ob2fNm1mtmW/otu9DMXjOzD7PvE8tsFkD5BrMb/1tJZ05Jco+kte4+Q9La7DGANlYYdnd/Q9JXZyxeIGlF9vMKSbeU3BeAktV7D7oOdz89CdhuSbk3YTOzxZIW1/k6AErS8A0n3d1TB97cfZmkZdLQPkAHDHX1Dr3tMbNOScq+95bXEoBmqDfsr0palP28SNIr5bQDoFkKx9nNbKWkH0qaJGmPpPskvSzpD5IulfS5pJ+4+5kH8QZ6riG7G5+a53zMmDHJdYvGbIuudy+6t3uqXrRuX19fst7ORoxIb6s6Oztza0X/7uE4zl74md3dF+aUftRQRwBaitNlgSAIOxAEYQeCIOxAEIQdCIJLXJFUNHQ3alR6QCd1K+uiy28vueSSZP3aa69N1nt6enJrmzdvTq77zTffJOvtjFtJA8ERdiAIwg4EQdiBIAg7EARhB4Ig7EAQDd+pBrGNGzcuWZ88eXJu7fXXX0+uW3S759Q02pK0fv363Nr111+fXHc4YssOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewzo6kovsdHDhwIFl/5plncmsTJkxIrlt0i+6ia8537dqVrEfDlh0IgrADQRB2IAjCDgRB2IEgCDsQBGEHguC+8YOUun96K9/Doaarqyu3NmvWrOS6d999d7K+Zs2aZP2hhx5K1oeruu8bb2bPm1mvmW3pt+x+M9tlZpuyr5vKbBZA+QazG/9bSfMGWP64u1+Vfa0uty0AZSsMu7u/IemrFvQCoIkaOUB3p5m9l+3mT8z7JTNbbGbdZtbdwGsBaFC9YX9W0vclXSWpR9Kjeb/o7svcfZa7p4/GAGiqusLu7nvcvc/dT0n6jaRrym0LQNnqCruZdfZ7+GNJW/J+F0B7KBxnN7OVkn4oaZKkPZLuyx5fJcklfSbp5+6ePxn2/z8XA9LDTNG921Pj7I3OgZ6af71qRfPaN/PcjLxx9sKbV7j7wgEWL2+4IwAtxemyQBCEHQiCsANBEHYgCMIOBMGtpJE0fvz4ZP3iiy9O1g8dOpRb27dvX3Ld48ePJ+tFUsNfo0al//SLpovev39/st6Olz2zZQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIBhnHwZSUxuPHj06ue4555yTrE+ePDlZLxpvTl2GWjQW3dHRkaynLp+VpMOHD+fWisbwd+zYkay34zh6EbbsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEUzYP0tixY+ted86cOcn6uHHjkvVFixYl69ddd11ureh69OXL0zcK3rBhQ7I+YkR6ezFz5szc2g033JBc94ILLkjWr7jiimT92LFjubXZs2cn150/f36yvmrVqmR948aNyXoz1T1lM4DhgbADQRB2IAjCDgRB2IEgCDsQBGEHgggzzl40he4dd9yRrD/44IO5tYkTJ9bVUzvo6+tL1h9//PFkvWg8+vLLLz/rnk4r+ttcunRpsv7kk0/m1qZMmZJc99NPP03WDx48mKw3es/7RtQ9zm5mU83sz2a2zcy2mtkvs+UXmtlrZvZh9n3o/sUDAQxmN/6kpH9295mSrpX0CzObKekeSWvdfYaktdljAG2qMOzu3uPuG7OfD0p6X1KXpAWSVmS/tkLSLc1qEkDjzuoedGY2TdIPJG2Q1OHup28wtlvSgDcMM7PFkhbX3yKAMgz6aLyZnSfpBUm/cvcD/WteO5Iy4NEUd1/m7rPcfVZDnQJoyKDCbmajVQv67939xWzxHjPrzOqdknqb0yKAMhTuxlttzGq5pPfd/bF+pVclLZL06+z7K03psCQzZsxI1p9++ukWdVK+1BBVashQku67776GXrvoVtIPPPBAbq3o8tjUJapS8WWqe/fuza29/PLLyXWLppMeigbzmf3vJN0mabOZbcqWLVEt5H8ws59J+lzST5rTIoAyFIbd3ddLyjsj5UfltgOgWThdFgiCsANBEHYgCMIOBEHYgSDCTNn85ZdfJuvr1q1L1nfu3JlbS43nStKRI0eS9aJLZB955JFkPdVbsy9hfvjhh5P1o0eP5taKbrFddBvs1atXJ+tPPPFEbq3o0t7hiC07EARhB4Ig7EAQhB0IgrADQRB2IAjCDgQR5lbSRa6++upkffv27bm1MWPGJNdNjTVL0qFDh5J14GwwZTMQHGEHgiDsQBCEHQiCsANBEHYgCMIOBME4OzDMMM4OBEfYgSAIOxAEYQeCIOxAEIQdCIKwA0EMZn72qZJ+J6lDkkta5u5Pmtn9kv5J0ukbsi9x9/SNvCtUNBd4bRr6al775MmTyXorz4XA8FV4Uo2ZdUrqdPeNZna+pHcl3aLafOx/cfd/H/SLVXhSDWFHFHkn1QxmfvYeST3ZzwfN7H1JXeW2B6DZzuozu5lNk/QDSRuyRXea2Xtm9ryZDTiHkZktNrNuM+tuqFMADRn0ufFmdp6kdZIedvcXzaxD0l7VPsc/qNqu/j8WPAe78QNgNx5laujceDMbLekFSb939xezJ9zj7n3ufkrSbyRdU1azAMpXGHarbfKWS3rf3R/rt7yz36/9WNKW8tsDUJbBHI2fLelNSZslncoWL5G0UNJVqu3Gfybp59nBvNRzte3+aNFufKre6EeEU6dOJeuNfAzgI0A8ebvxXM+eIewYLrieHQiOsANBEHYgCMIOBEHYgSAIOxAEQ29DQNHQHcNr6I+hNyA4wg4EQdiBIAg7EARhB4Ig7EAQhB0IovCGkyXbK+nzfo8nZcvaUdv0dsY4etv0NQB6q0+Zvf11XqGlJ9V858XNut19VmUNJLRrb+3al0Rv9WpVb+zGA0EQdiCIqsO+rOLXT2nX3tq1L4ne6tWS3ir9zA6gdaresgNoEcIOBFFJ2M1snpltN7OPzOyeKnrIY2afmdlmM9tU9fx02Rx6vWa2pd+yC83sNTP7MPs+4Bx7FfV2v5ntyt67TWZ2U0W9TTWzP5vZNjPbama/zJZX+t4l+mrJ+9byz+xmNlLSB5LmSPpC0juSFrr7tpY2ksPMPpM0y90rPwHDzK6X9BdJv3P3v8mW/Zukr9z919l/lBPd/V/apLf7dZbTeDept7xpxv9BFb53ZU5/Xo8qtuzXSPrI3T9x9+OSVklaUEEfbc/d35D01RmLF0hakf28QrU/lpbL6a0tuHuPu2/Mfj4o6fQ045W+d4m+WqKKsHdJ2tnv8Rdqr/neXdKfzOxdM1tcdTMD6Og3zdZuSR1VNjOAwmm8W+mMacbb5r2rZ/rzRnGA7rtmu/vfSrpR0i+y3dW25LXPYO00dvqspO+rNgdgj6RHq2wmm2b8BUm/cvcD/WtVvncD9NWS962KsO+SNLXf4ynZsrbg7ruy772SXlL7TUW95/QMutn33or7+T/tNI33QNOMqw3euyqnP68i7O9ImmFm083sHEk/lfRqBX18h5mNzw6cyMzGS5qr9puK+lVJi7KfF0l6pcJevqVdpvHOm2ZcFb93lU9/7u4t/5J0k2pH5D+W9K9V9JDT1/ck/Xf2tbXq3iStVG237oRqxzZ+JukiSWslfSjpvyRd2Ea9/YdqU3u/p1qwOivqbbZqu+jvSdqUfd1U9XuX6Ksl7xunywJBcIAOCIKwA0EQdiAIwg4EQdiBIAg7EARhB4L4X5HSVqqIIA5UAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"LyYTurCUTldo","executionInfo":{"status":"ok","timestamp":1620920833310,"user_tz":-330,"elapsed":1186,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}}},"source":["l2dists = []\n","for i in range(128):\n","  x_l2 = cw_adv_stab[i,:,:,:]\n","  l2dist = np.sum((x_l2-test_data[i,:,:,:])**2)\n","  l2dists.append(l2dist)"],"execution_count":73,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IjiB_UiaTmmq","executionInfo":{"status":"ok","timestamp":1620920836769,"user_tz":-330,"elapsed":1374,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}},"outputId":"2be1d5b4-8a9d-4920-8a0c-57213962504d"},"source":["l2dists = np.array(l2dists)\n","print(np.mean(l2dists), np.max(l2dists), np.median(l2dists), np.min(l2dists))\n","print(np.sum(l2dists < 2))\n","print(np.argmax(l2dists))"],"execution_count":74,"outputs":[{"output_type":"stream","text":["6.741137 30.09211 6.636635 0.00017929226\n","28\n","35\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dK2V4_JQBa68","executionInfo":{"status":"ok","timestamp":1620917694784,"user_tz":-330,"elapsed":1061,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}}},"source":["def test_attack_single_input(model, adv, x, true_label, num_trials=10, std=0.01):\n","    # original input\n","    y = model(x)\n","    pred_label = np.argmax(y)\n","    count = np.zeros(10)\n","    for i in range(num_trials):\n","        x_noisy = x + np.random.normal(scale=std, size=x.shape)\n","        y_noisy = model(x_noisy)\n","        noisy_label = np.argmax(y_noisy)\n","        count[noisy_label] += 1\n","    noisy_label = np.argmax(count)\n","\n","    # adv. input\n","    y_adv = model(adv)\n","    adv_label = np.argmax(y_adv)\n","    count = np.zeros(10)\n","    for i in range(num_trials):\n","        adv_noisy = adv + np.random.normal(scale=std, size=adv.shape)\n","        y_noisy_adv = model(adv_noisy)\n","        noisy_label_adv = np.argmax(y_noisy_adv)\n","        count[noisy_label_adv] += 1\n","    adv_noisy_label = np.argmax(count)\n","    print('\\r', 'true:', true_label, 'pred:', pred_label, 'noisy_pred:', noisy_label, 'adv_pred:', adv_label, 'adv_noisy_pred:', adv_noisy_label, end='')\n","\n","    return true_label, pred_label, noisy_label, adv_label, adv_noisy_label\n","\n","def test_attack_multiple_inputs(model, cw_adv, num_runs=100):\n","    corr = 0\n","    noisy_corr = 0\n","    adv_corr = 0\n","    adv_noisy_corr = 0\n","    for run in range(num_runs):\n","        i = np.random.randint(0, 128)\n","        x = test_data[i,:,:,:][np.newaxis,:,:,:]\n","        adv = cw_adv[i,:,:,:][np.newaxis,:,:,:]\n","        true, pred, noisy_pred, adv_pred, adv_noisy_pred = test_attack_single_input(model, adv, x, test_labels[i], num_trials=10, std=.8)\n","        corr += (pred == true)\n","        noisy_corr += (true == noisy_pred)\n","        adv_corr += (true == adv_pred)\n","        adv_noisy_corr += (true == adv_noisy_pred)\n","    print(f'\\nAcc Original: {corr/num_runs}, Acc Adv: {adv_corr/num_runs}, Acc Adv Noisy: {adv_noisy_corr/num_runs}, Acc Ori Noisy: {noisy_corr/num_runs}')\n"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1vVFLMU-Bgxk","executionInfo":{"status":"ok","timestamp":1620917620063,"user_tz":-330,"elapsed":10204,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}},"outputId":"8b880a62-5956-46fc-f111-bc2aca687f0a"},"source":["test_attack_multiple_inputs(basic_model, cw_adv_basic)"],"execution_count":33,"outputs":[{"output_type":"stream","text":[" true: 7 pred: 7 noisy_pred: 7 adv_pred: 8 adv_noisy_pred: 8\n","Acc Original: 1.0, Acc Adv: 0.17, Acc Adv Noisy: 0.21, Acc Ori Noisy: 0.99\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"40PCmEtFO4_R","executionInfo":{"status":"ok","timestamp":1620917870143,"user_tz":-330,"elapsed":10055,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}},"outputId":"f70d9385-ce61-48d5-cf31-d7e049e89b70"},"source":["test_attack_multiple_inputs(pgd_model, cw_adv_pgd)"],"execution_count":41,"outputs":[{"output_type":"stream","text":[" true: 9 pred: 9 noisy_pred: 8 adv_pred: 2 adv_noisy_pred: 8\n","Acc Original: 1.0, Acc Adv: 0.1, Acc Adv Noisy: 0.02, Acc Ori Noisy: 0.09\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPjsr_UcMqy-","executionInfo":{"status":"ok","timestamp":1620917706071,"user_tz":-330,"elapsed":10113,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}},"outputId":"63fa8c99-b8dc-4a0e-e98f-e4ddf8fbb8fd"},"source":["test_attack_multiple_inputs(stab_model, cw_adv_stab)"],"execution_count":38,"outputs":[{"output_type":"stream","text":[" true: 9 pred: 9 noisy_pred: 9 adv_pred: 7 adv_noisy_pred: 9\n","Acc Original: 1.0, Acc Adv: 0.15, Acc Adv Noisy: 0.34, Acc Ori Noisy: 0.95\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0ztSkZLJP3pt","executionInfo":{"status":"ok","timestamp":1620918941334,"user_tz":-330,"elapsed":1410,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}}},"source":["def test_robustness_single_input(model, adv, x, true_label, std=0.01, num_trials=100, alpha=2):\n","    y = model(x)\n","    pred_label = np.argmax(y)\n","    count = np.zeros(10)\n","    for i in range(num_trials):\n","        x_noisy = x + np.random.normal(scale=std, size=x.shape)\n","        y_noisy = model(x_noisy)\n","        noisy_label = np.argmax(y_noisy)\n","        count[noisy_label] += 1\n","    noisy_label = np.argmax(count)\n","    # total_counts = np.sum(count)\n","    # p1 = count[noisy_label] / total_counts\n","    # count[noisy_label] = -1\n","    # p2 = count[np.argmax(count)] / total_counts\n","\n","\n","    y_adv = model(adv)\n","    adv_label = np.argmax(y_adv)\n","    count = np.zeros(10)\n","    for i in range(num_trials):\n","        adv_noisy = adv + np.random.normal(scale=std, size=adv.shape)\n","        y_noisy_adv = model(adv_noisy)\n","        noisy_label_adv = np.argmax(y_noisy_adv)\n","        count[noisy_label_adv] += 1\n","    noisy_label_adv = np.argmax(count)\n","    total_counts = np.sum(count)\n","    p1 = count[noisy_label_adv] / total_counts\n","    count[noisy_label_adv] = -1\n","    p2 = count[np.argmax(count)] / total_counts\n","\n","    alpha = 1.001\n","    while True:\n","        alpha *= 2\n","        if - 2*std**2 / alpha * np.log(1e-9+1-p1-p2+2*(1/2 * (p1**(1-alpha) + p2**(1-alpha))**(1/(1-alpha)) )) >= 0:\n","            L = np.sqrt(- 2*std**2 / alpha * np.log(1-p1-p2+2*(1/2 * (p1**(1-alpha) + p2**(1-alpha))**(1/(1-alpha)) ))) if p2 != 0 else 0.4\n","            break\n","    print('\\r', pred_label, noisy_label, adv_label, noisy_label_adv, L, end='')\n","    return true_label, noisy_label, pred_label, adv_label, noisy_label_adv, count, L\n","\n","def test_robustness_multiple_inputs(model, cw_adv, std=.5, num_trials=10, num_runs=100):\n","    score = 0\n","    L_avg = 0\n","    in_domain_score = 0\n","    count_in_domain = 0\n","    in_domain_similar = 0\n","    corr = 0\n","    noisy_corr = 0\n","    adv_corr = 0\n","    adv_noisy_corr = 0\n","    for run in range(num_runs):\n","        i = np.random.randint(0, 128)\n","        adv = cw_adv[i,:,:,:][np.newaxis,:,:,:]\n","        true, pred, noisy_pred, adv_pred, adv_noisy_pred, count, L = test_robustness_single_input(model, adv, test_data[i,:,:,:][np.newaxis,:,:,:], test_labels[i], num_trials=num_trials, std=std)\n","        corr += (pred == true)\n","        noisy_corr += (true == noisy_pred)\n","        adv_corr += (true == adv_pred)\n","        adv_noisy_corr += (true == adv_noisy_pred)\n","\n","        if L >= np.sum((adv-test_data[i,:,:,:])**2):\n","            count_in_domain += 1\n","            in_domain_score += (true == adv_noisy_pred)\n","            in_domain_similar += (noisy_pred == adv_noisy_pred)\n","    # print(score)\n","    print(f'\\nAcc Original: {corr/num_runs}, Acc Adv: {adv_corr/num_runs}, Acc Adv Noisy: {adv_noisy_corr/num_runs}, Acc Ori Noisy: {noisy_corr/num_runs}, In domain sim: {in_domain_similar / (count_in_domain+1e-9)}, In domain acc: {in_domain_score / (count_in_domain+1e-9)}, In domain counts: {count_in_domain}')\n","    # L_avg = L_avg / score if score != 0 else -1\n","    # return score / num_runs, L_avg"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I4IsSB4-SaqX","executionInfo":{"status":"ok","timestamp":1620920858054,"user_tz":-330,"elapsed":9343,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}},"outputId":"60e13c2c-8b66-497b-d10e-8728f231ebd7"},"source":["test_robustness_multiple_inputs(stab_model, cw_adv_stab)"],"execution_count":75,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: RuntimeWarning: divide by zero encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":[" 1 1 1 1 0.4\n","Acc Original: 0.99, Acc Adv: 0.26, Acc Adv Noisy: 0.4, Acc Ori Noisy: 1.0, In domain sim: 0.9629629629272977, In domain acc: 0.9629629629272977, In domain counts: 27\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15HU7-PoUX5t","executionInfo":{"status":"ok","timestamp":1620919304676,"user_tz":-330,"elapsed":9631,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}},"outputId":"4413cf10-5071-41bc-87f7-9bc17c6a90c5"},"source":["test_robustness_multiple_inputs(basic_model, cw_adv_basic)"],"execution_count":58,"outputs":[{"output_type":"stream","text":["\r 8 8 5 5 0.67634190991157\r 1 1 5 3 0.5119308624119282\r 7 7 3 3 0.4"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: RuntimeWarning: divide by zero encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":[" 0 0 2 2 0.7753858255701761\n","Acc Original: 0.94, Acc Adv: 0.15, Acc Adv Noisy: 0.18, Acc Ori Noisy: 1.0, In domain sim: 0.9999999999285715, In domain acc: 0.9999999999285715, In domain counts: 14\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4PVPZM8xUaLt","executionInfo":{"status":"ok","timestamp":1620919349945,"user_tz":-330,"elapsed":10301,"user":{"displayName":"Vedant Agarwal","photoUrl":"https://lh6.googleusercontent.com/-hX3xaLoXBLQ/AAAAAAAAAAI/AAAAAAAADp8/Qw5Ra-fJ5-c/s64/photo.jpg","userId":"08554397736642895977"}},"outputId":"e2e88211-f012-4edd-faae-f35fa34e7fe9"},"source":["test_robustness_multiple_inputs(pgd_model, cw_adv_pgd)"],"execution_count":59,"outputs":[{"output_type":"stream","text":[" 9 4 1 8 0.5835901319604132"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: RuntimeWarning: divide by zero encountered in double_scalars\n"],"name":"stderr"},{"output_type":"stream","text":[" 4 4 9 8 0.5967304142118187\n","Acc Original: 0.67, Acc Adv: 0.17, Acc Adv Noisy: 0.03, Acc Ori Noisy: 1.0, In domain sim: 0.0, In domain acc: 0.0, In domain counts: 0\n"],"name":"stdout"}]}]}