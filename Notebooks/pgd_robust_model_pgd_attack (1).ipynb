{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pgd-robust-model-pgd-attack.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrSJxAwZDGXc",
        "outputId": "4884fec2-b1e8-4513-90c6-cd7c5e6889e3"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_v2_behavior()\n",
        "tf.compat.v1.enable_eager_execution(\n",
        "    config=None, device_policy=None, execution_mode=None\n",
        ")\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_sSFHr0DJfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af9eae7a-206c-4050-f09b-69f6335b1a8c"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
        "train_data, test_data = train_data / 255.0, test_data / 255.0\n",
        "\n",
        "# Add a channels dimension\n",
        "train_data = train_data[..., tf.newaxis].astype(\"float32\")\n",
        "test_data = test_data[..., tf.newaxis].astype(\"float32\")\n",
        "\n",
        "\n",
        "VALIDATION_SIZE = 5000\n",
        "validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
        "validation_labels = train_labels[:VALIDATION_SIZE]\n",
        "train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
        "train_labels = train_labels[VALIDATION_SIZE:]\n",
        "params = [32, 32, 64, 64, 200, 200]\n",
        "batch_size = 128\n",
        "\n",
        "# Prepare the training dataset.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "# Prepare the validation dataset.\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((validation_data, validation_labels))\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "class MNIST:\n",
        "    def __init__(self, train_data, train_labels, validation_data, validation_labels, test_data, test_labels):\n",
        "        self.train_data = train_data\n",
        "        self.train_labels = train_labels\n",
        "        self.test_data = test_data\n",
        "        self.test_labels = test_labels\n",
        "        self.validation_data = validation_data\n",
        "        self.validation_labels = validation_labels\n",
        "\n",
        "mnist_data = MNIST(train_data, train_labels, validation_data, validation_labels, test_data, test_labels)\n",
        "\n",
        "\n",
        "def show(img):\n",
        "    \"\"\"\n",
        "    Show MNSIT digits in the console.\n",
        "    \"\"\"\n",
        "    remap = \"  .*#\"+\"#\"*100\n",
        "    img = (img.flatten()+.5)*3\n",
        "    if len(img) != 784: return\n",
        "    print(\"START\")\n",
        "    for i in range(28):\n",
        "        print(\"\".join([remap[int(round(x))] for x in img[i*28:i*28+28]]))\n",
        "\n",
        "def get_model(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n",
        "    \"\"\"\n",
        "    Standard neural network training procedure.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    print(data.train_data.shape)\n",
        "    \n",
        "    model.add(Conv2D(params[0], (3, 3),\n",
        "                            input_shape=data.train_data.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(params[1], (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(params[2], (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(params[3], (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(params[4]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(params[5]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_madry_model(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n",
        "    \"\"\"\n",
        "    Standard neural network training procedure.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    print(data.train_data.shape)\n",
        "    \n",
        "    model.add(Conv2D(32, (5, 5), padding=\"same\",\n",
        "                            input_shape=data.train_data.shape[1:]))\n",
        "    # model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
        "    model.add(Conv2D(64, (5, 5), padding=\"same\"))\n",
        "    # model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    # model.add(Activation('relu'))\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_madry_little_diff_model(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n",
        "    \"\"\"\n",
        "    Standard neural network training procedure.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    print(data.train_data.shape)\n",
        "    \n",
        "    model.add(Conv2D(32, (3, 3),\n",
        "                            input_shape=data.train_data.shape[1:]))\n",
        "    # model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    # model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    # model.add(Activation('relu'))\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_madry_with_relu_model(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n",
        "    \"\"\"\n",
        "    Standard neural network training procedure.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    print(data.train_data.shape)\n",
        "    \n",
        "    model.add(Conv2D(32, (5, 5), padding=\"same\",\n",
        "                            input_shape=data.train_data.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
        "    model.add(Conv2D(64, (5, 5), padding=\"same\"))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbDZU8IbDVaQ",
        "outputId": "212bf865-46cf-4193-e284-eb24bf588eff"
      },
      "source": [
        "pgd_model = get_model(mnist_data, \"mnistModel\", params)\n",
        "\n",
        "import keras\n",
        "# Instantiate an optimizer to train the model.\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9)\n",
        "# Instantiate a loss function.\n",
        "loss_fn1 = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "loss_fn2 = keras.losses.BinaryCrossentropy()\n",
        "loss_fn3 = keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n",
        "\n",
        "# Prepare the metrics.\n",
        "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "\n",
        "# @tf.function\n",
        "def train_step(x1, x2, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits1 = pgd_model(x1, training=True)\n",
        "        logits2 = pgd_model(x2, training=True)\n",
        "        loss_value = tf.add(loss_fn1(y, logits1), loss_fn1(y, logits2))\n",
        "    grads = tape.gradient(loss_value, pgd_model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, pgd_model.trainable_weights))\n",
        "    train_acc_metric.update_state(y, logits1)\n",
        "    return loss_value\n",
        "\n",
        "# @tf.function\n",
        "def test_step(x, y):\n",
        "    val_logits = pgd_model(x, training=False)\n",
        "    val_acc_metric.update_state(y, val_logits)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNVtyMW8hXrD",
        "outputId": "ef93db26-2854-4e62-bbc5-4efd65f304d4"
      },
      "source": [
        "print(basic_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 14, 14, 64)        51264     \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1024)              3212288   \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                10250     \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 3,274,634\n",
            "Trainable params: 3,274,634\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOc6GNdCAuOl"
      },
      "source": [
        "\"\"\"\n",
        "Implementation of attack methods. Running this file as a program will\n",
        "apply the attack to the model specified by the config file and store\n",
        "the examples in an .npy file.\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "class LinfPGDAttack:\n",
        "  def __init__(self, model, epsilon, k, a, random_start, loss_func):\n",
        "    \"\"\"Attack parameter initialization. The attack performs k steps of\n",
        "       size a, while always staying within epsilon from the initial\n",
        "       point.\"\"\"\n",
        "    self.model = pgd_model\n",
        "    self.epsilon = epsilon\n",
        "    self.k = k\n",
        "    self.a = a\n",
        "    self.rand = random_start\n",
        "\n",
        "  def perturb(self, x_nat, y):\n",
        "    \"\"\"Given a set of examples (x_nat, y), returns a set of adversarial\n",
        "       examples within epsilon of x_nat in l_infinity norm.\"\"\"\n",
        "    if self.rand:\n",
        "        x = x_nat + np.random.uniform(-self.epsilon, self.epsilon, x_nat.shape)\n",
        "        x = np.clip(x, 0, 1) # ensure valid pixel range\n",
        "    else:\n",
        "        x = np.copy(x_nat)\n",
        "\n",
        "    for i in range(self.k):\n",
        "        x_tensor = tf.convert_to_tensor(x)\n",
        "        with tf.GradientTape() as t:\n",
        "            t.watch(x_tensor)\n",
        "            x_image = tf.reshape(x_tensor, [-1,28,28,1])\n",
        "            logits1 = pgd_model(x_image, training=True)\n",
        "            loss_value = loss_fn3(y, logits1)\n",
        "        result = loss_value\n",
        "        grad = t.gradient(loss_value, x_tensor)\n",
        "        \n",
        "        x += self.a * np.sign(grad)\n",
        "\n",
        "        x = np.clip(x, x_nat - self.epsilon, x_nat + self.epsilon) \n",
        "        x = np.clip(x, 0, 1) # ensure valid pixel range\n",
        "\n",
        "    return x\n",
        "import json\n",
        "import sys\n",
        "import math\n",
        "\n",
        "\n",
        "attack = LinfPGDAttack(pgd_model,\n",
        "                        0.3,\n",
        "                        40,\n",
        "                        0.01,\n",
        "                        True,\n",
        "                        \"xent\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq5xeIowFhjR",
        "outputId": "aca83aa2-9500-4d46-e9e5-1ad7d2c7a747"
      },
      "source": [
        "# Training model\n",
        "import time\n",
        "import math \n",
        "std = 0.01\n",
        "epochs = 5\n",
        "\n",
        "total_steps = sum(1 for _ in train_dataset)\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        x_batch_adv = attack.perturb(x_batch_train, y_batch_train).reshape(-1,28,28,1)\n",
        "        # Compute loss\n",
        "        loss_value = train_step(x_batch_train, x_batch_adv, y_batch_train)\n",
        "        print('\\r', \"Epoch %d\" % (epoch,), 'Training step:', step+1, f'/{total_steps}', 'Loss:', float(loss_value), 'Acc:', float(train_acc_metric.result()), end='')\n",
        "    \n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"\\nTraining acc over epoch: %.4f\" % (float(train_acc),), end=' ')\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        test_step(x_batch_val, y_batch_val)\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_acc_metric.reset_states()\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),), end=' ')\n",
        "    print(\"Time taken: %.2fs\\n\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Epoch 0 Training step: 430 /430 Loss: 0.9834176301956177 Acc: 0.7883636355400085\n",
            "Training acc over epoch: 0.7884 Validation acc: 0.9724 Time taken: 254.24s\n",
            "\n",
            " Epoch 1 Training step: 430 /430 Loss: 0.5100302696228027 Acc: 0.9666908979415894\n",
            "Training acc over epoch: 0.9667 Validation acc: 0.9818 Time taken: 222.09s\n",
            "\n",
            " Epoch 2 Training step: 430 /430 Loss: 0.1945931762456894 Acc: 0.9770545363426208\n",
            "Training acc over epoch: 0.9771 Validation acc: 0.9836 Time taken: 220.99s\n",
            "\n",
            " Epoch 3 Training step: 430 /430 Loss: 0.21423320472240448 Acc: 0.981218159198761\n",
            "Training acc over epoch: 0.9812 Validation acc: 0.9888 Time taken: 219.18s\n",
            "\n",
            " Epoch 4 Training step: 430 /430 Loss: 0.1365857720375061 Acc: 0.9849454760551453\n",
            "Training acc over epoch: 0.9849 Validation acc: 0.9890 Time taken: 218.33s\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SomnrB1VGs7M",
        "outputId": "7b60717e-690f-4b7f-d583-a56bb1e36f6f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "tf.keras.models.save_model(pgd_model, '/content/drive/MyDrive/CS726/pgd_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26yh7dzNGXP5",
        "outputId": "0661b0c0-a20e-4397-9e83-458a93e739f7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTfXcV-kGc91"
      },
      "source": [
        "tf.keras.models.save_model(pgd_model, '/content/drive/Shareddrives/AML-Project/Trained Models/pgd_model')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5frlIG7SdP8",
        "outputId": "10576390-20d6-4a99-b9cf-d55162944835"
      },
      "source": [
        "x_tensor1 = tf.convert_to_tensor(train_data[1:3,:,:,:].reshape(-1,784))\n",
        "y1 = train_labels[1:3]\n",
        "with tf.GradientTape() as t:\n",
        "    t.watch(x_tensor1)\n",
        "    x_input = tf.reshape(x_tensor1, [-1,28,28,1])\n",
        "    logits11 = basic_model(x_input, training=True)\n",
        "    loss_value3 = loss_fn3(y1, logits11)\n",
        "    loss_value1 = loss_fn1(y1, logits11)\n",
        "result = loss_value1\n",
        "grad = t.gradient(loss_value3, x_tensor1)\n",
        "print(loss_value1, loss_value3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.02583846, shape=(), dtype=float32) tf.Tensor(0.05167692, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUej_TFwS3qj",
        "outputId": "b72744d7-cff1-4d56-97e4-30c076f7765c"
      },
      "source": [
        "print(grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-2.3741059e-06 -2.4822975e-06 -4.2244160e-06 ...  6.7994904e-08\n",
            "  -7.2581656e-07 -1.2402419e-06]\n",
            " [ 8.1715118e-03  6.3168872e-03  6.6806478e-03 ...  3.4910217e-03\n",
            "   1.2533757e-03 -4.7204274e-04]], shape=(2, 784), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jtfq9En0XNvG",
        "outputId": "e3832686-f470-44e9-910b-0611f211cfc5"
      },
      "source": [
        "print(grad.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2Lu4Z5_CKuq"
      },
      "source": [
        "\"\"\"\n",
        "Implementation of attack methods. Running this file as a program will\n",
        "apply the attack to the model specified by the config file and store\n",
        "the examples in an .npy file.\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "class LinfPGDAttack:\n",
        "  def __init__(self, model, epsilon, k, a, random_start, loss_func):\n",
        "    \"\"\"Attack parameter initialization. The attack performs k steps of\n",
        "       size a, while always staying within epsilon from the initial\n",
        "       point.\"\"\"\n",
        "    self.model = model\n",
        "    self.epsilon = epsilon\n",
        "    self.k = k\n",
        "    self.a = a\n",
        "    self.rand = random_start\n",
        "\n",
        "  def perturb(self, x_nat, y):\n",
        "    \"\"\"Given a set of examples (x_nat, y), returns a set of adversarial\n",
        "       examples within epsilon of x_nat in l_infinity norm.\"\"\"\n",
        "    if self.rand:\n",
        "        x = x_nat + np.random.uniform(-self.epsilon, self.epsilon, x_nat.shape)\n",
        "        x = np.clip(x, 0, 1) # ensure valid pixel range\n",
        "    else:\n",
        "        x = np.copy(x_nat)\n",
        "\n",
        "    for i in range(self.k):\n",
        "        x_tensor = tf.convert_to_tensor(x)\n",
        "        with tf.GradientTape() as t:\n",
        "            t.watch(x_tensor)\n",
        "            x_image = tf.reshape(x_tensor, [-1,28,28,1])\n",
        "            logits1 = pgd_model(x_image, training=True)\n",
        "            loss_value = loss_fn3(y, logits1)\n",
        "        result = loss_value\n",
        "        grad = t.gradient(loss_value, x_tensor)\n",
        "        \n",
        "        x += self.a * np.sign(grad)\n",
        "\n",
        "        x = np.clip(x, x_nat - self.epsilon, x_nat + self.epsilon) \n",
        "        x = np.clip(x, 0, 1) # ensure valid pixel range\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwkkHbvJDBYS"
      },
      "source": [
        "import json\n",
        "import sys\n",
        "import math\n",
        "\n",
        "\n",
        "attack = LinfPGDAttack(pgd_model,\n",
        "                        0.3,\n",
        "                        100,\n",
        "                        0.01,\n",
        "                        True,\n",
        "                        \"xent\")\n",
        "\n",
        "\n",
        "\n",
        "# Iterate over the samples batch-by-batch\n",
        "num_eval_examples = 10000\n",
        "eval_batch_size = 128\n",
        "num_batches = int(math.ceil(num_eval_examples / eval_batch_size))\n",
        "\n",
        "x_adv = [] # adv accumulator\n",
        "\n",
        "print('Iterating over {} batches'.format(num_batches))\n",
        "\n",
        "for ibatch in range(num_batches):\n",
        "    bstart = ibatch * eval_batch_size\n",
        "    bend = min(bstart + eval_batch_size, num_eval_examples)\n",
        "    print('batch size: {}'.format(bend - bstart))\n",
        "\n",
        "    x_batch = test_data[bstart:bend, :, :, :].reshape(-1,784)\n",
        "    y_batch = test_labels[bstart:bend]\n",
        "\n",
        "    x_batch_adv = attack.perturb(x_batch, y_batch).reshape(-1,28,28,1)\n",
        "    x_adv.append(x_batch_adv)\n",
        "\n",
        "print('Storing examples')\n",
        "path = 'pgd_attack_pgd_model.npy'\n",
        "x_adv = np.concatenate(x_adv, axis=0)\n",
        "np.save(path, x_adv)\n",
        "print('Examples stored in {}'.format(path))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi6EDLUuGCew"
      },
      "source": [
        "pgd_adv = np.load('pgd_attack_pgd_model.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKzNbF9OG-CS"
      },
      "source": [
        "# pgd_adv = np.load('/content/drive/Shareddrives/AML-Project/LinfSecondOrder/pgd_attack2-linf.npy')\n",
        "pgd_adv = test_data"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S931OttFGlhX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70fffc42-bffa-464b-daa6-e3981956d5b5"
      },
      "source": [
        "i = 10\n",
        "x_linf = pgd_adv[i,:,:,:]\n",
        "show(x_linf)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "im_linf = x_linf.reshape(28, 28)\n",
        "plt.gray()\n",
        "plt.imshow(im_linf)\n",
        "plt.figure()\n",
        "plt.imshow(test_data[i,:,:,:].reshape(28,28))\n",
        "print(test_labels[i])\n",
        "print(np.sum((x_linf-test_data[i,:,:,:])**2))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "START\n",
            "............................\n",
            "............................\n",
            "............................\n",
            "............................\n",
            "..............*#**..........\n",
            "..........##########........\n",
            ".........*###########.......\n",
            ".........###......*###......\n",
            ".........##*.......*##......\n",
            ".........#*.........##*.....\n",
            "........##*.........*##.....\n",
            "........##...........##.....\n",
            ".......*##...........##.....\n",
            ".......##............##.....\n",
            ".......##............##.....\n",
            ".......##............##.....\n",
            "......*##...........*##.....\n",
            "......*##...........##......\n",
            "......*##..........*##......\n",
            ".......##.........*##.......\n",
            ".......##.......*###........\n",
            ".......############*........\n",
            "........##########*.........\n",
            ".........######**...........\n",
            "............................\n",
            "............................\n",
            "............................\n",
            "............................\n",
            "0\n",
            "0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANpklEQVR4nO3df+hVdZ7H8dcrV/+xojJWtImdioimaPshIayt1TBDW1L5jyk0tWTYjwlmaIUNVxohBmzZaemvQslyF7dhSIdkWnJa+zVmhPZj1bSZLIxRvmVipVIwa773j+9x+I597+d+vffce26+nw/4cu8973vueXPp1Tn3fM7x44gQgBPfSU03AKA/CDuQBGEHkiDsQBKEHUjir/q5Mduc+gd6LCI82vKu9uy2r7P9e9s7bT/QzWcB6C13Os5ue5ykP0j6gaTdkjZJmhcR2wvrsGcHeqwXe/YrJe2MiA8j4k+Sfinppi4+D0APdRP2syT9ccTr3dWyv2B7ge3Ntjd3sS0AXer5CbqIWCZpmcRhPNCkbvbseySdPeL1d6plAAZQN2HfJOl82+fYniBprqS19bQFoG4dH8ZHxGHb90laJ2mcpBUR8W5tnQGoVcdDbx1tjN/sQM/15KIaAN8ehB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0dcpm9EbM2bMaFl7/fXXi+tecMEFxfqsWbOK9RtuuKFYf+6554r1ko0bNxbrGzZs6PizM2LPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMIvrADj11FOL9VWrVhXr1157bcvaV199VVx3woQJxfrJJ59crPdSu96//PLLYv2ee+5pWXvmmWc66unboNUsrl1dVGN7l6SDkr6WdDgipnXzeQB6p44r6K6JiH01fA6AHuI3O5BEt2EPSb+1/abtBaO9wfYC25ttb+5yWwC60O1h/IyI2GP7ryW9YPu9iHh15BsiYpmkZRIn6IAmdbVnj4g91eNeSb+WdGUdTQGoX8dhtz3R9ilHn0v6oaRtdTUGoF4dj7PbPlfDe3Np+OfAf0XEz9usw2H8KB577LFi/a677urZtnfs2FGsf/rpp8X6gQMHOt62Pepw8J+1u1e+nYMHD7asXXXVVcV1t2zZ0tW2m1T7OHtEfCjpbzvuCEBfMfQGJEHYgSQIO5AEYQeSIOxAEtzi2gcXXXRRsf7yyy8X65MmTSrWd+/e3bJ22223FdfduXNnsf75558X64cOHSrWS046qbyvefDBB4v1xYsXF+vjxo1rWVuzZk1x3TvvvLNY/+yzz4r1JrUaemPPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMGVzH5xyyinFertx9HbXQjz88MMta+3G8Jt05MiRYn3JkiXFert/BnvhwoUta7Nnzy6uu2LFimK9m6mom8KeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4H72Ppg5c2ax/tJLLxXrTz31VLF+xx13HG9LKXzwwQcta+ecc05x3SeffLJYnz9/fkc99QP3swPJEXYgCcIOJEHYgSQIO5AEYQeSIOxAEtzP3gcPPfRQV+u/8cYbNXWSy7p161rW7r777uK606dPr7udxrXds9teYXuv7W0jlp1h+wXb71ePp/e2TQDdGsth/FOSrjtm2QOS1kfE+ZLWV68BDLC2YY+IVyXtP2bxTZJWVs9XSrq55r4A1KzT3+yTI2Koev6xpMmt3mh7gaQFHW4HQE26PkEXEVG6wSUilklaJuW9EQYYBJ0OvX1ie4okVY9762sJQC90Gva1km6vnt8u6dl62gHQK20P420/LelqSWfa3i3pZ5KWSvqV7fmSPpI0p5dNDrpzzz23WJ86dWqx/sUXXxTrW7duPe6eIL344osta+3G2U9EbcMeEfNalL5fcy8AeojLZYEkCDuQBGEHkiDsQBKEHUiCW1xrcOuttxbr7YbmVq9eXaxv3LjxuHsCjsWeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJy9BnPnzi3W293C+uijj9bZDjAq9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7H3w3nvvFesbNmzoUyfIjD07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPsYTZw4sWVt/PjxfewE6EzbPbvtFbb32t42YtkS23tsv1P9Xd/bNgF0ayyH8U9Jum6U5f8eEZdWf/9db1sA6tY27BHxqqT9fegFQA91c4LuPttbqsP801u9yfYC25ttb+5iWwC61GnYH5N0nqRLJQ1J+kWrN0bEsoiYFhHTOtwWgBp0FPaI+CQivo6II5KWS7qy3rYA1K2jsNueMuLlbEnbWr0XwGBoO85u+2lJV0s60/ZuST+TdLXtSyWFpF2S7uphjwNhzpw5LWvnnXdecd19+/bV3Q7G4MYbb+x43cOHD9fYyWBoG/aImDfK4id60AuAHuJyWSAJwg4kQdiBJAg7kARhB5LgFld8a11xxRXF+qxZszr+7EWLFnW87qBizw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOjoHVbhz9/vvvL9ZPO+20lrXXXnutuO66deuK9W8j9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7GO0a9eulrWDBw/2r5ETyLhx44r1hQsXFuu33HJLsb5nz56OP/tE/Kek2bMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKOiP5tzO7fxvpo+/btxXq773jmzJnF+iBP+XzJJZcU6/fee2/L2uWXX15cd9q0aR31dNQ111zTsvbKK6909dmDLCI82vK2e3bbZ9t+yfZ22+/a/km1/AzbL9h+v3o8ve6mAdRnLIfxhyX9U0R8T9J0ST+2/T1JD0haHxHnS1pfvQYwoNqGPSKGIuKt6vlBSTsknSXpJkkrq7etlHRzr5oE0L3jujbe9nclXSbpDUmTI2KoKn0saXKLdRZIWtB5iwDqMOaz8bZPlrRa0k8j4sDIWgyfgRr1LFRELIuIaRHR3dkWAF0ZU9htj9dw0FdFxJpq8Se2p1T1KZL29qZFAHVoexhv25KekLQjIh4ZUVor6XZJS6vHZ3vS4QngwgsvLNaff/75Yn1oaKhYb9L06dOL9UmTJnX82e2GHNeuXVusb9q0qeNtn4jG8pv97yT9SNJW2+9UyxZpOOS/sj1f0keS5vSmRQB1aBv2iNggadRBeknfr7cdAL3C5bJAEoQdSIKwA0kQdiAJwg4kwS2uNZg9e3axvnjx4mL9sssuq7OdgXLkyJGWtf379xfXfeSRR4r1pUuXdtTTia7jW1wBnBgIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtn7YOrUqcV6u/vZL7744jrbqdXy5cuL9bfffrtl7fHHH6+7HYhxdiA9wg4kQdiBJAg7kARhB5Ig7EAShB1IgnF24ATDODuQHGEHkiDsQBKEHUiCsANJEHYgCcIOJNE27LbPtv2S7e2237X9k2r5Ett7bL9T/V3f+3YBdKrtRTW2p0iaEhFv2T5F0puSbtbwfOyHIuLfxrwxLqoBeq7VRTVjmZ99SNJQ9fyg7R2Szqq3PQC9dly/2W1/V9Jlkt6oFt1ne4vtFbZPb7HOAtubbW/uqlMAXRnztfG2T5b0iqSfR8Qa25Ml7ZMUkh7S8KH+HW0+g8N4oMdaHcaPKey2x0v6jaR1EfGN2faqPf5vIqL4LyMSdqD3Or4RxrYlPSFpx8igVyfujpotaVu3TQLonbGcjZ8h6XeStko6Ov/uIknzJF2q4cP4XZLuqk7mlT6LPTvQY10dxteFsAO9x/3sQHKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJNr+g5M12yfpoxGvz6yWDaJB7W1Q+5LorVN19vY3rQp9vZ/9Gxu3N0fEtMYaKBjU3ga1L4neOtWv3jiMB5Ig7EASTYd9WcPbLxnU3ga1L4neOtWX3hr9zQ6gf5reswPoE8IOJNFI2G1fZ/v3tnfafqCJHlqxvcv21moa6kbnp6vm0Ntre9uIZWfYfsH2+9XjqHPsNdTbQEzjXZhmvNHvrunpz/v+m932OEl/kPQDSbslbZI0LyK297WRFmzvkjQtIhq/AMP230s6JOk/jk6tZftfJe2PiKXV/yhPj4h/HpDelug4p/HuUW+tphn/RzX43dU5/XknmtizXylpZ0R8GBF/kvRLSTc10MfAi4hXJe0/ZvFNklZWz1dq+D+WvmvR20CIiKGIeKt6flDS0WnGG/3uCn31RRNhP0vSH0e83q3Bmu89JP3W9pu2FzTdzCgmj5hm62NJk5tsZhRtp/Hup2OmGR+Y766T6c+7xQm6b5oREZdL+gdJP64OVwdSDP8GG6Sx08cknafhOQCHJP2iyWaqacZXS/ppRBwYWWvyuxulr758b02EfY+ks0e8/k61bCBExJ7qca+kX2v4Z8cg+eToDLrV496G+/mziPgkIr6OiCOSlqvB766aZny1pFURsaZa3Ph3N1pf/fremgj7Jknn2z7H9gRJcyWtbaCPb7A9sTpxItsTJf1QgzcV9VpJt1fPb5f0bIO9/IVBmca71TTjavi7a3z684jo+5+k6zV8Rv4DSf/SRA8t+jpX0v9Wf+823ZukpzV8WPd/Gj63MV/SJEnrJb0v6X8knTFAvf2nhqf23qLhYE1pqLcZGj5E3yLpnerv+qa/u0JfffneuFwWSIITdEAShB1IgrADSRB2IAnCDiRB2IEkCDuQxP8D0wdNeotu5ewAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQvb0zHnFF54"
      },
      "source": [
        "def test_attack_single_input(adv, x, true_label, num_trials=10, std=0.01):\n",
        "    # original input\n",
        "    y = pgd_model(x)\n",
        "    pred_label = np.argmax(y)\n",
        "    count = np.zeros(10)\n",
        "    for i in range(num_trials):\n",
        "        x_noisy = x + np.random.normal(scale=std, size=x.shape)\n",
        "        y_noisy = pgd_model(x_noisy)\n",
        "        noisy_label = np.argmax(y_noisy)\n",
        "        count[noisy_label] += 1\n",
        "    noisy_label = np.argmax(count)\n",
        "\n",
        "    # adv. input\n",
        "    y_adv = pgd_model(adv)\n",
        "    adv_label = np.argmax(y_adv)\n",
        "    count = np.zeros(10)\n",
        "    for i in range(num_trials):\n",
        "        adv_noisy = adv + np.random.normal(scale=std, size=adv.shape)\n",
        "        y_noisy_adv = pgd_model(adv_noisy)\n",
        "        noisy_label_adv = np.argmax(y_noisy_adv)\n",
        "        count[noisy_label_adv] += 1\n",
        "    adv_noisy_label = np.argmax(count)\n",
        "    print('\\r', 'true:', true_label, 'pred:', pred_label, 'noisy_pred:', noisy_label, 'adv_pred:', adv_label, 'adv_noisy_pred:', adv_noisy_label, end='')\n",
        "\n",
        "    return true_label, pred_label, noisy_label, adv_label, adv_noisy_label\n",
        "\n",
        "def test_attack_multiple_inputs(num_runs=100):\n",
        "    corr = 0\n",
        "    noisy_corr = 0\n",
        "    adv_corr = 0\n",
        "    adv_noisy_corr = 0\n",
        "    for run in range(num_runs):\n",
        "        i = np.random.randint(0, 10000)\n",
        "        x = test_data[i,:,:,:][np.newaxis,:,:,:]\n",
        "        adv = pgd_adv[i,:,:,:][np.newaxis,:,:,:]\n",
        "        true, pred, noisy_pred, adv_pred, adv_noisy_pred = test_attack_single_input(adv, x, test_labels[i], num_trials=10, std=0.1)\n",
        "        corr += (pred == true)\n",
        "        noisy_corr += (true == noisy_pred)\n",
        "        adv_corr += (true == adv_pred)\n",
        "        adv_noisy_corr += (true == adv_noisy_pred)\n",
        "    print(f'\\nAcc Original: {corr/num_runs}, Acc Adv: {adv_corr/num_runs}, Acc Adv Noisy: {adv_noisy_corr/num_runs}, Acc Ori Noisy: {noisy_corr/num_runs}')\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mDpXu3DZnys"
      },
      "source": [
        "a = 1\n",
        "a += (1==2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8gVCntNZq2K"
      },
      "source": [
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfI_nEMYGHZM",
        "outputId": "dc2ba584-7e58-469e-c639-f466a2b761ce"
      },
      "source": [
        "test_attack_multiple_inputs()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " true: 2 pred: 2 noisy_pred: 2 adv_pred: 2 adv_noisy_pred: 0\n",
            "Acc Original: 1.0, Acc Adv: 0.86, Acc Adv Noisy: 0.82, Acc Ori Noisy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7WhTMeRHPGL",
        "outputId": "2b6db088-2a21-41ce-838b-3fd0703969bf"
      },
      "source": [
        "test_attack_multiple_inputs()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " true: 5 pred: 2 noisy_pred: 2 adv_pred: 2 adv_noisy_pred: 2\n",
            "Acc Original: 0.05, Acc Adv: 0.05, Acc Adv Noisy: 0.06, Acc Ori Noisy: 0.05\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}