{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pgd-attack.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GrSJxAwZDGXc","executionInfo":{"status":"ok","timestamp":1620915292886,"user_tz":-330,"elapsed":3293,"user":{"displayName":"Rishi Agarwal","photoUrl":"","userId":"13706671974881542882"}},"outputId":"39ca542b-aa36-4fa1-d586-89c065091489"},"source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import SGD\n","\n","import tensorflow as tf\n","tf.compat.v1.disable_v2_behavior()\n","tf.compat.v1.enable_eager_execution(\n","    config=None, device_policy=None, execution_mode=None\n",")\n","import keras"],"execution_count":1,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o_sSFHr0DJfD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620915300062,"user_tz":-330,"elapsed":10465,"user":{"displayName":"Rishi Agarwal","photoUrl":"","userId":"13706671974881542882"}},"outputId":"23fccbb2-ad4b-4131-ec3e-57c290fbee2d"},"source":["mnist = tf.keras.datasets.mnist\n","\n","(train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n","train_data, test_data = train_data / 255.0, test_data / 255.0\n","\n","# Add a channels dimension\n","train_data = train_data[..., tf.newaxis].astype(\"float32\")\n","test_data = test_data[..., tf.newaxis].astype(\"float32\")\n","\n","\n","VALIDATION_SIZE = 5000\n","validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n","validation_labels = train_labels[:VALIDATION_SIZE]\n","train_data = train_data[VALIDATION_SIZE:, :, :, :]\n","train_labels = train_labels[VALIDATION_SIZE:]\n","params = [32, 32, 64, 64, 200, 200]\n","batch_size = 128\n","\n","# Prepare the training dataset.\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n","train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n","\n","# Prepare the validation dataset.\n","val_dataset = tf.data.Dataset.from_tensor_slices((validation_data, validation_labels))\n","val_dataset = val_dataset.batch(batch_size)\n","\n","class MNIST:\n","    def __init__(self, train_data, train_labels, validation_data, validation_labels, test_data, test_labels):\n","        self.train_data = train_data\n","        self.train_labels = train_labels\n","        self.test_data = test_data\n","        self.test_labels = test_labels\n","        self.validation_data = validation_data\n","        self.validation_labels = validation_labels\n","\n","mnist_data = MNIST(train_data, train_labels, validation_data, validation_labels, test_data, test_labels)\n","\n","\n","def show(img):\n","    \"\"\"\n","    Show MNSIT digits in the console.\n","    \"\"\"\n","    remap = \"  .*#\"+\"#\"*100\n","    img = (img.flatten()+.5)*3\n","    if len(img) != 784: return\n","    print(\"START\")\n","    for i in range(28):\n","        print(\"\".join([remap[int(round(x))] for x in img[i*28:i*28+28]]))\n","\n","def get_model(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n","    \"\"\"\n","    Standard neural network training procedure.\n","    \"\"\"\n","    model = Sequential()\n","\n","    print(data.train_data.shape)\n","    \n","    model.add(Conv2D(params[0], (3, 3),\n","                            input_shape=data.train_data.shape[1:]))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(params[1], (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Conv2D(params[2], (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(params[3], (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Flatten())\n","    model.add(Dense(params[4]))\n","    model.add(Activation('relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(params[5]))\n","    model.add(Activation('relu'))\n","    model.add(Dense(10))\n","    model.add(Activation('softmax'))\n","\n","    return model\n","\n","def get_madry_model(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n","    \"\"\"\n","    Standard neural network training procedure.\n","    \"\"\"\n","    model = Sequential()\n","\n","    print(data.train_data.shape)\n","    \n","    model.add(Conv2D(32, (5, 5), padding=\"same\",\n","                            input_shape=data.train_data.shape[1:]))\n","    # model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n","    model.add(Conv2D(64, (5, 5), padding=\"same\"))\n","    # model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n","\n","    model.add(Flatten())\n","    model.add(Dense(1024))\n","    # model.add(Activation('relu'))\n","    model.add(Dense(10))\n","    model.add(Activation('softmax'))\n","\n","    return model\n","\n","def get_madry_little_diff_model(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n","    \"\"\"\n","    Standard neural network training procedure.\n","    \"\"\"\n","    model = Sequential()\n","\n","    print(data.train_data.shape)\n","    \n","    model.add(Conv2D(32, (3, 3),\n","                            input_shape=data.train_data.shape[1:]))\n","    # model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Conv2D(64, (3, 3)))\n","    # model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Flatten())\n","    model.add(Dense(1024))\n","    # model.add(Activation('relu'))\n","    model.add(Dense(10))\n","    model.add(Activation('softmax'))\n","\n","    return model\n","\n","def get_madry_with_relu_model(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n","    \"\"\"\n","    Standard neural network training procedure.\n","    \"\"\"\n","    model = Sequential()\n","\n","    print(data.train_data.shape)\n","    \n","    model.add(Conv2D(32, (5, 5), padding=\"same\",\n","                            input_shape=data.train_data.shape[1:]))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n","    model.add(Conv2D(64, (5, 5), padding=\"same\"))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n","\n","    model.add(Flatten())\n","    model.add(Dense(1024))\n","    model.add(Activation('relu'))\n","    model.add(Dense(10))\n","    model.add(Activation('softmax'))\n","\n","    return model"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HbDZU8IbDVaQ","executionInfo":{"status":"ok","timestamp":1620915300063,"user_tz":-330,"elapsed":10459,"user":{"displayName":"Rishi Agarwal","photoUrl":"","userId":"13706671974881542882"}},"outputId":"2633ee90-c0d6-4c5c-cd38-0bd6c930bcf3"},"source":["basic_model = get_model(mnist_data, \"mnistModel\", params)\n","\n","import keras\n","# Instantiate an optimizer to train the model.\n","optimizer = keras.optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9)\n","# Instantiate a loss function.\n","loss_fn1 = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","loss_fn2 = keras.losses.BinaryCrossentropy()\n","loss_fn3 = keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n","\n","# Prepare the metrics.\n","train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","\n","# @tf.function\n","def train_step(x1, y):\n","    with tf.GradientTape() as tape:\n","        logits1 = basic_model(x1, training=True)\n","        loss_value = loss_fn1(y, logits1)\n","    grads = tape.gradient(loss_value, basic_model.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, basic_model.trainable_weights))\n","    train_acc_metric.update_state(y, logits1)\n","    return loss_value\n","\n","# @tf.function\n","def test_step(x, y):\n","    val_logits = basic_model(x, training=False)\n","    val_acc_metric.update_state(y, val_logits)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["(55000, 28, 28, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lNVtyMW8hXrD","executionInfo":{"status":"ok","timestamp":1620554235820,"user_tz":-330,"elapsed":1107,"user":{"displayName":"vandana agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgT6WsVCLEHejHx8X3q_3eC17uaQDSV02dSTc-9=s64","userId":"05138740150841605865"}},"outputId":"ef93db26-2854-4e62-bbc5-4efd65f304d4"},"source":["print(basic_model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_12 (Conv2D)           (None, 28, 28, 32)        832       \n","_________________________________________________________________\n","activation_14 (Activation)   (None, 28, 28, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_10 (MaxPooling (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","conv2d_13 (Conv2D)           (None, 14, 14, 64)        51264     \n","_________________________________________________________________\n","activation_15 (Activation)   (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_11 (MaxPooling (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","flatten_5 (Flatten)          (None, 3136)              0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 1024)              3212288   \n","_________________________________________________________________\n","activation_16 (Activation)   (None, 1024)              0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 10)                10250     \n","_________________________________________________________________\n","activation_17 (Activation)   (None, 10)                0         \n","=================================================================\n","Total params: 3,274,634\n","Trainable params: 3,274,634\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aq5xeIowFhjR","executionInfo":{"status":"ok","timestamp":1620915409225,"user_tz":-330,"elapsed":94510,"user":{"displayName":"Rishi Agarwal","photoUrl":"","userId":"13706671974881542882"}},"outputId":"81db3e10-06aa-4c07-9314-ef0922202a4e"},"source":["# Training model\n","import time\n","import math \n","std = 0.01\n","epochs = 5\n","\n","total_steps = sum(1 for _ in train_dataset)\n","for epoch in range(epochs):\n","    start_time = time.time()\n","\n","    # Iterate over the batches of the dataset.\n","    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","        # Compute loss\n","        loss_value = train_step(x_batch_train, y_batch_train)\n","        print('\\r', \"Epoch %d\" % (epoch,), 'Training step:', step+1, f'/{total_steps}', 'Loss:', float(loss_value), 'Acc:', float(train_acc_metric.result()), end='')\n","    \n","    # Display metrics at the end of each epoch.\n","    train_acc = train_acc_metric.result()\n","    print(\"\\nTraining acc over epoch: %.4f\" % (float(train_acc),), end=' ')\n","\n","    # Reset training metrics at the end of each epoch\n","    train_acc_metric.reset_states()\n","\n","    # Run a validation loop at the end of each epoch.\n","    for x_batch_val, y_batch_val in val_dataset:\n","        test_step(x_batch_val, y_batch_val)\n","    val_acc = val_acc_metric.result()\n","    val_acc_metric.reset_states()\n","    print(\"Validation acc: %.4f\" % (float(val_acc),), end=' ')\n","    print(\"Time taken: %.2fs\\n\" % (time.time() - start_time))"],"execution_count":4,"outputs":[{"output_type":"stream","text":[" Epoch 0 Training step: 430 /430 Loss: 0.22438444197177887 Acc: 0.7936000227928162\n","Training acc over epoch: 0.7936 Validation acc: 0.9682 Time taken: 42.85s\n","\n"," Epoch 1 Training step: 430 /430 Loss: 0.047443702816963196 Acc: 0.9617090821266174\n","Training acc over epoch: 0.9617 Validation acc: 0.9824 Time taken: 12.76s\n","\n"," Epoch 2 Training step: 430 /430 Loss: 0.01357968058437109 Acc: 0.9728545546531677\n","Training acc over epoch: 0.9729 Validation acc: 0.9822 Time taken: 12.57s\n","\n"," Epoch 3 Training step: 430 /430 Loss: 0.21093526482582092 Acc: 0.9776545166969299\n","Training acc over epoch: 0.9777 Validation acc: 0.9858 Time taken: 12.39s\n","\n"," Epoch 4 Training step: 430 /430 Loss: 0.026699639856815338 Acc: 0.9820181727409363\n","Training acc over epoch: 0.9820 Validation acc: 0.9866 Time taken: 12.31s\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gk_qDPXXFTAq","executionInfo":{"status":"ok","timestamp":1620915439738,"user_tz":-330,"elapsed":30481,"user":{"displayName":"Rishi Agarwal","photoUrl":"","userId":"13706671974881542882"}},"outputId":"38ca1910-0f02-4810-b1b5-417bef9869ce"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","tf.keras.models.save_model(basic_model, '/content/drive/MyDrive/CS726/basic_model')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5frlIG7SdP8","executionInfo":{"status":"ok","timestamp":1620553786432,"user_tz":-330,"elapsed":760,"user":{"displayName":"vandana agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgT6WsVCLEHejHx8X3q_3eC17uaQDSV02dSTc-9=s64","userId":"05138740150841605865"}},"outputId":"10576390-20d6-4a99-b9cf-d55162944835"},"source":["x_tensor1 = tf.convert_to_tensor(train_data[1:3,:,:,:].reshape(-1,784))\n","y1 = train_labels[1:3]\n","with tf.GradientTape() as t:\n","    t.watch(x_tensor1)\n","    x_input = tf.reshape(x_tensor1, [-1,28,28,1])\n","    logits11 = basic_model(x_input, training=True)\n","    loss_value3 = loss_fn3(y1, logits11)\n","    loss_value1 = loss_fn1(y1, logits11)\n","result = loss_value1\n","grad = t.gradient(loss_value3, x_tensor1)\n","print(loss_value1, loss_value3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tf.Tensor(0.02583846, shape=(), dtype=float32) tf.Tensor(0.05167692, shape=(), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZUej_TFwS3qj","executionInfo":{"status":"ok","timestamp":1620553795785,"user_tz":-330,"elapsed":1343,"user":{"displayName":"vandana agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgT6WsVCLEHejHx8X3q_3eC17uaQDSV02dSTc-9=s64","userId":"05138740150841605865"}},"outputId":"b72744d7-cff1-4d56-97e4-30c076f7765c"},"source":["print(grad)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[-2.3741059e-06 -2.4822975e-06 -4.2244160e-06 ...  6.7994904e-08\n","  -7.2581656e-07 -1.2402419e-06]\n"," [ 8.1715118e-03  6.3168872e-03  6.6806478e-03 ...  3.4910217e-03\n","   1.2533757e-03 -4.7204274e-04]], shape=(2, 784), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jtfq9En0XNvG","executionInfo":{"status":"ok","timestamp":1620553155572,"user_tz":-330,"elapsed":1149,"user":{"displayName":"vandana agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgT6WsVCLEHejHx8X3q_3eC17uaQDSV02dSTc-9=s64","userId":"05138740150841605865"}},"outputId":"e3832686-f470-44e9-910b-0611f211cfc5"},"source":["print(grad.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(2, 784)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t2Lu4Z5_CKuq","executionInfo":{"status":"ok","timestamp":1620915439739,"user_tz":-330,"elapsed":30478,"user":{"displayName":"Rishi Agarwal","photoUrl":"","userId":"13706671974881542882"}}},"source":["\"\"\"\n","Implementation of attack methods. Running this file as a program will\n","apply the attack to the model specified by the config file and store\n","the examples in an .npy file.\n","\"\"\"\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","# import tensorflow as tf\n","# import numpy as np\n","\n","\n","class LinfPGDAttack:\n","  def __init__(self, model, epsilon, k, a, random_start, loss_func):\n","    \"\"\"Attack parameter initialization. The attack performs k steps of\n","       size a, while always staying within epsilon from the initial\n","       point.\"\"\"\n","    self.model = model\n","    self.epsilon = epsilon\n","    self.k = k\n","    self.a = a\n","    self.rand = random_start\n","\n","  def perturb(self, x_nat, y):\n","    \"\"\"Given a set of examples (x_nat, y), returns a set of adversarial\n","       examples within epsilon of x_nat in l_infinity norm.\"\"\"\n","    if self.rand:\n","        x = x_nat + np.random.uniform(-self.epsilon, self.epsilon, x_nat.shape)\n","        x = np.clip(x, 0, 1) # ensure valid pixel range\n","    else:\n","        x = np.copy(x_nat)\n","\n","    for i in range(self.k):\n","        x_tensor = tf.convert_to_tensor(x)\n","        with tf.GradientTape() as t:\n","            t.watch(x_tensor)\n","            x_image = tf.reshape(x_tensor, [-1,28,28,1])\n","            logits1 = basic_model(x_image, training=True)\n","            loss_value = loss_fn3(y, logits1)\n","        result = loss_value\n","        grad = t.gradient(loss_value, x_tensor)\n","        \n","        x += self.a * np.sign(grad)\n","\n","        x = np.clip(x, x_nat - self.epsilon, x_nat + self.epsilon) \n","        x = np.clip(x, 0, 1) # ensure valid pixel range\n","\n","    return x"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwkkHbvJDBYS"},"source":["import json\n","import sys\n","import math\n","\n","\n","attack = LinfPGDAttack(basic_model,\n","                        0.3,\n","                        40,\n","                        0.01,\n","                        True,\n","                        \"xent\")\n","\n","\n","\n","# Iterate over the samples batch-by-batch\n","num_eval_examples = 10000\n","eval_batch_size = 128\n","num_batches = int(math.ceil(num_eval_examples / eval_batch_size))\n","\n","x_adv = [] # adv accumulator\n","\n","print('Iterating over {} batches'.format(num_batches))\n","\n","for ibatch in range(num_batches):\n","    bstart = ibatch * eval_batch_size\n","    bend = min(bstart + eval_batch_size, num_eval_examples)\n","    print('batch size: {}'.format(bend - bstart))\n","\n","    x_batch = test_data[bstart:bend, :, :, :].reshape(-1,784)\n","    y_batch = test_labels[bstart:bend]\n","\n","    x_batch_adv = attack.perturb(x_batch, y_batch).reshape(-1,28,28,1)\n","    x_adv.append(x_batch_adv)\n","\n","print('Storing examples')\n","path = 'pgd_attack2.npy'\n","x_adv = np.concatenate(x_adv, axis=0)\n","np.save(path, x_adv)\n","print('Examples stored in {}'.format(path))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fi6EDLUuGCew","executionInfo":{"status":"ok","timestamp":1620915513498,"user_tz":-330,"elapsed":1394,"user":{"displayName":"Rishi Agarwal","photoUrl":"","userId":"13706671974881542882"}}},"source":["pgd_adv = np.load('pgd_attack2.npy')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"S931OttFGlhX"},"source":["i = 0\n","x_linf = pgd_adv[i,:,:,:]\n","show(x_linf)\n","\n","import matplotlib.pyplot as plt\n","\n","im_linf = x_linf.reshape(28, 28)\n","plt.gray()\n","plt.imshow(im_linf)\n","plt.figure()\n","plt.imshow(test_data[i,:,:,:].reshape(28,28))\n","print(test_labels[i])\n","print(np.sum((x_linf-test_data[i,:,:,:])**2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQvb0zHnFF54","executionInfo":{"status":"ok","timestamp":1620915526399,"user_tz":-330,"elapsed":1142,"user":{"displayName":"Rishi Agarwal","photoUrl":"","userId":"13706671974881542882"}}},"source":["def test_attack_single_input(adv, x, true_label, num_trials=10, std=0.01):\n","    # original input\n","    y = basic_model(x)\n","    pred_label = np.argmax(y)\n","    count = np.zeros(10)\n","    for i in range(num_trials):\n","        x_noisy = x + np.random.normal(scale=std, size=x.shape)\n","        y_noisy = basic_model(x_noisy)\n","        noisy_label = np.argmax(y_noisy)\n","        count[noisy_label] += 1\n","    noisy_label = np.argmax(count)\n","\n","    # adv. input\n","    y_adv = basic_model(adv)\n","    adv_label = np.argmax(y_adv)\n","    count = np.zeros(10)\n","    for i in range(num_trials):\n","        adv_noisy = adv + np.random.normal(scale=std, size=adv.shape)\n","        y_noisy_adv = basic_model(adv_noisy)\n","        noisy_label_adv = np.argmax(y_noisy_adv)\n","        count[noisy_label_adv] += 1\n","    adv_noisy_label = np.argmax(count)\n","    print('\\r', 'true:', true_label, 'pred:', pred_label, 'noisy_pred:', noisy_label, 'adv_pred:', adv_label, 'adv_noisy_pred:', adv_noisy_label, end='')\n","\n","    return true_label, pred_label, noisy_label, adv_label, adv_noisy_label\n","\n","def test_attack_multiple_inputs(num_runs=100):\n","    corr = 0\n","    noisy_corr = 0\n","    adv_corr = 0\n","    adv_noisy_corr = 0\n","    for run in range(num_runs):\n","        i = np.random.randint(0, 10000)\n","        x = test_data[i,:,:,:][np.newaxis,:,:,:]\n","        adv = pgd_adv[i,:,:,:][np.newaxis,:,:,:]\n","        true, pred, noisy_pred, adv_pred, adv_noisy_pred = test_attack_single_input(adv, x, test_labels[i], num_trials=10, std=0.1)\n","        corr += (pred == true)\n","        noisy_corr += (true == noisy_pred)\n","        adv_corr += (true == adv_pred)\n","        adv_noisy_corr += (true == adv_noisy_pred)\n","    print(f'\\nAcc Original: {corr/num_runs}, Acc Adv: {adv_corr/num_runs}, Acc Adv Noisy: {adv_noisy_corr/num_runs}, Acc Ori Noisy: {noisy_corr/num_runs}')\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"_mDpXu3DZnys"},"source":["a = 1\n","a += (1==2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U8gVCntNZq2K"},"source":["print(a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lfI_nEMYGHZM","executionInfo":{"status":"ok","timestamp":1620915543231,"user_tz":-330,"elapsed":13754,"user":{"displayName":"Rishi Agarwal","photoUrl":"","userId":"13706671974881542882"}},"outputId":"10d06bbe-cdd8-49c4-ae58-18bc6621b5c7"},"source":["test_attack_multiple_inputs()"],"execution_count":11,"outputs":[{"output_type":"stream","text":[" true: 4 pred: 4 noisy_pred: 4 adv_pred: 9 adv_noisy_pred: 9\n","Acc Original: 1.0, Acc Adv: 0.02, Acc Adv Noisy: 0.02, Acc Ori Noisy: 1.0\n"],"name":"stdout"}]}]}